{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Generalized Mean.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"iJcsOuDcKXun"},"source":["<h1>The Generalized Mean Function<h1>\n","\n","# I. Summary\n","\n","Both the **generalized_mean** and **generalized_mean_alt** functions are robust to small numbers close to the limits of precision, so we should use the simpler **generalized_mean** function.\n","\n","# II. Function Descriptions\n","\n","The cell below holds the **generalized_mean** and **generalized_mean_alt** functions, which depend on the **coupled_logarithm** and **coupled_exponential** functions. They take in 1-D numpy array of non-negative numbers (*values*), a risk-bias parameter (*r*), which must be numeric and is the power of the generalized mean, and a 1-D numpy array of weights (creatively called *weights*) for calculating weighted generalized means. If *weights* equals False, equal weighting of each value is used. The **generalized_mean_alt** function has an additional parameter called *norm_factor* that is discussed more below.\n","\n","Both functions first calculate the log-generalized mean using the coupled logarithm, and then exponentiates it to calculate the generalized mean.\n","\n","The log-generalized mean is calculated as: \n","\n","### $\\text{ln}_{r}\\text{(generalized mean)} = \\frac{1}{\\Sigma^n_{i=1}w_i}\\Sigma^{n}_{i=1}w_i\\text{ln}_{r}(x_{i})$\n","\n","The generalized mean is calculated as:\n","\n","### $\\text{generalized mean} = \\text{exp}_{r} \\text{(ln}_{r} \\text{(generalized mean))}$\n","\n","For the **generalized_mean_alt** function, $\\text{ln}_{r}(x_{i})$ is calculated as:\n","\n","### $\\text{log}_{r}(x_{i}) = q \\frac{1}{q} \\text{log}_{r}(x_{i}) = q \\frac{1}{q} \\frac{1}{r}(x_{i}^{r}-1) = q \\frac{1}{qr}(x_{i}^{r}-1) = q \\frac{1}{qr}(x_{i}^{\\frac{qr}{q}}-1) = q \\text{log}_{qr}(x_{i}^{\\frac{1}{q}})$\n","\n","where $q$ is the normalization factor (*norm_factor*).\n","\n","The tests for the **generalized_mean** and **generalized_mean_alt** functions are below the cell defining the functions."]},{"cell_type":"code","metadata":{"id":"ZgjORflQKXuw","executionInfo":{"status":"ok","timestamp":1607649361941,"user_tz":300,"elapsed":513,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}}},"source":["import numpy as np\n","import pandas as pd\n","import math\n","from typing import Any, List  # for NDArray types\n","\n","def generalized_mean(values: np.ndarray, r: float = 1.0, weights: np.ndarray = False) -> float:\n","    \"\"\"\n","    This function calculates the generalized mean of a 1-D array of non- \n","    negative real numbers using the coupled logarithm and exponential functions.\n","    \n","    Parameters\n","    ----------\n","    values : np.ndarray\n","        DESCRIPTION : A 1-D numpy array (row vector) of non-negative numbers\n","         for which we are calculating the generalized mean.\n","    r : float, optional\n","        DESCRIPTION : The risk bias and the power of the generalized mean. \n","        The default is 1.0 (Arithmetric Mean).\n","    weights : np.ndarray, optional\n","        DESCRIPTION : A 1-D numpy array of the weights for each value. \n","        The default is False, which triggers a conditional to use equal weights.\n","\n","    Returns gen_mean\n","    -------\n","    float\n","        DESCRIPTION : The coupled generalized mean.\n","    \"\"\"\n","    \n","    # If weights equals False, equally weight all observations.\n","    if weights == False:\n","        # Create an array of all ones equal in length to values.\n","        weights = np.ones(len(values))\n","    \n","    # Calculate the log of the generalized mean by taking the dot product of the\n","    # weights vector and the vector of the coupled logarithm of the values and\n","    # divide the result by the sum of the the weights.\n","    log_gen_mean = np.dot(weights, coupled_logarithm(values, kappa=r, dim=0)) / np.sum(weights)\n","        \n","    # Calculate the generalized mean by exponentiating the log-generalized mean.\n","    gen_mean = coupled_exponential(log_gen_mean, kappa=r, dim=0)\n","    \n","    # Return the generalized mean.\n","    return gen_mean\n","\n","def generalized_mean_alt(values: np.ndarray, r: float = 1.0, weights: np.ndarray = False, norm_factor: int = 1) -> float:\n","    \"\"\"\n","    This function calculates the generalized mean of a 1-D array of non- \n","    negative real numbers using the coupled logarithm and exponential functions.\n","    \n","    Parameters\n","    ----------\n","    values : np.ndarray\n","        DESCRIPTION : A 1-D numpy array (row vector) of non-negative numbers\n","         for which we are calculating the generalized mean.\n","    r : float, optional\n","        DESCRIPTION : The risk bias and the power of the generalized mean. \n","        The default is 1.0 (Arithmetric Mean).\n","    weights : np.ndarray, optional\n","        DESCRIPTION : A 1-D numpy array of the weights for each value. \n","        The default is False, which triggers a conditional to use equal weights.\n","    norm_factor : int\n","        DESCRIPTION : An integer whose inverse the values array is raised to,\n","        -r is multiplied by for the coupled_logarithm function call, and then the\n","        result is multiplied by to calculate the coupled log of the values.\n","        log_r(values) = norm_factor * log_(norm_factor*r)(values^(1/norm_factor))\n","        The default is 1.\n","    \n","    Returns gen_mean\n","    -------\n","    float\n","        DESCRIPTION : The coupled generalized mean.\n","    \"\"\"\n","    \n","    # If weights equals False, equally weight all observations.\n","    if weights == False:\n","        # Create an array of all ones equal in length to values.\n","        weights = np.ones(len(values))\n","    \n","    # Calculate the log of the generalized mean by taking the dot product of the\n","    # weights vector and the vector of the coupled logarithm of the values and\n","    # divide the result by the sum of the the weights.\n","    coupled_log_values = norm_factor * coupled_logarithm(values**(1/norm_factor), kappa=r*norm_factor, dim=0)\n","    log_gen_mean = np.dot(weights, coupled_log_values) / np.sum(weights)\n","        \n","    # Calculate the generalized mean by exponentiating the log-generalized mean.\n","    gen_mean = coupled_exponential(log_gen_mean, kappa=r, dim=0)\n","    \n","    # Return the generalized mean.\n","    return gen_mean\n","\n","def coupled_logarithm(value: [float, Any], kappa: float = 0.0, dim: int = 1) -> [float, Any]:\n","    \"\"\"\n","    Generalization of the logarithm function, which defines smooth\n","    transition to power functions.\n","    Inputs\n","    ----------\n","    x : Input variable in which the coupled logarithm is applied to.\n","    kappa : Coupling parameter which modifies the coupled logarithm function.\n","    dim : The dimension of x, or rank if x is a tensor. Not needed?\n","    \"\"\"\n","    if isinstance(value, float):    \n","        assert value >= 0, \"x must be greater or equal to 0.\"  # Greater than 0?????\n","    else:\n","        assert isinstance(value, np.ndarray), \"x must be a np.ndarray type if a sequence, or a float if a scalar.\"\n","        # assert np.all(x), \"all values in x must be \"\n","\n","    if kappa == 0:\n","        coupled_log_value = np.log(value)  # divide by 0 if x == 0\n","    else:\n","        coupled_log_value = (1 / kappa) * (value**(kappa / (1 + dim*kappa)) - 1)\n","    return coupled_log_value\n","\n","\n","def coupled_exponential(value: float, kappa: float = 0.0, dim: int = 1) -> float:\n","    \"\"\"\n","    Short description\n","    ----------\n","    x : Input variable in which the coupled exponential is applied to.\n","    kappa : Coupling parameter which modifies the coupled exponential function.\n","    dim : The dimension of x, or rank if x is a tensor.\n","    \"\"\"\n","    assert dim >= 0, \"dim must be greater than or equal 0.\"\n","        # may also want to test that dim is an integer\n","\n","        # removed the requirement on kappa; although not common kappa can be less than -1/dim\n","    if kappa == 0:\n","        coupled_exp_value = math.exp(value)\n","    else:\n","        if kappa > 0:\n","        \tcoupled_exp_value = (1 + kappa*value)**(1/(kappa / (1 + dim*kappa))) # removed negative sign and added reciprocal\n","        # now given that kappa < 0\n","        elif (1 + kappa*value) >= 0:\n","       \t\tcoupled_exp_value = (1 + kappa*value)**(1/(kappa / (1 + dim*kappa))) # removed negative sign and added reciprocal\n","        elif (kappa / (1 + dim*kappa)) > 0: # removed negative sign\n","       \t\tcoupled_exp_value = 0\n","        else:\n","       \t\tcoupled_exp_value = float('inf')\n","        # else:\n","        # \tprint(\"Error: kappa = 1/d is not greater than -1.\")\n","    return coupled_exp_value"],"execution_count":184,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kon6gppQKXu0"},"source":["# III. Quick Tests\n","\n","To test the **generalized_mean** function, I tested the harmonic ($p = -1$), $-\\frac{2}{3}$ ($p = -\\frac{2}{3}$), geometric ($p = 0$), and arithmetic ($p = 1$) means. For the harmonic, geometric, and arithmetic means, I compared the outputs of the **generalized_mean** and **generalized_mean_alt** functions to built-in functions in numpy and scipy.\n","\n","Each of the four generalized means were tested on the random vectors $\\vec{X} = [X_1, X_2, ..., X_n]$, where $X_i \\overset{\\text{iid}}{\\sim} \\text{N }(100, 25)$ and $\\vec{Y} = [Y_1, Y_2, ..., Y_n]$, where $Y_i \\overset{\\text{iid}}{\\sim} \\text{Beta }(0.0001, 0.1)$, for $i \\in \\{1, 2, ..., n\\}$ and $n=1,000,000$. A random seed is used, so the functions are tested on realizations of the random vectors. They are now referred to as $\\vec{x}$ and $\\vec{y}$. For $\\vec{y}$, I had to filter out numbers too small for double precision floats and were set to $0$. Of the $1,000,000$ original values, $71,602$ values passed this filter.\n","\n","$\\vec{x}$ is meant to compare the functions on numbers that are not very small or large. $\\vec{y}$ is meant to compare the functions on very small numbers that are not too small for the 64 bit float data type. Smaller numbers might require more memory to store.\n","\n","On both $\\vec{x}$ and $\\vec{y}$, the **generalized_mean** and **generalized_mean_alt** functions give answers very close to the built-in functions for the harmonic, geometric, and arithmetic means."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"TDJSWVPkKXu2","executionInfo":{"status":"ok","timestamp":1607649362456,"user_tz":300,"elapsed":1011,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"4f4e143d-6478-491c-9b80-7f998ba165ea"},"source":["# Import the function to calculate harmonic means from a scipy module.\n","from scipy.stats.mstats import hmean\n","# Import the function to calculate geometric means from a scipy module.\n","from scipy.stats.mstats import gmean\n","\n","# Set the size of each numpy array of pseudo-random numbers.\n","n = 1000000\n","\n","# Set a random seed for reproducibility.\n","np.random.seed(0)\n","\n","# Generate n pseudo-random numbers from a N(100, 25) distribution.\n","x = np.random.normal(loc=100, scale=5, size=n)\n","# Generate n pseudo-random numbers from a Beta(0.01, 1) distribution.\n","y = np.random.beta(0.0001, 0.1, size=n)\n","# Filter out the y-values so small they equal 0.\n","y = y[y != 0]\n","\n","\n","print(f'{y.shape[0]:,} values of {n:,} y values are large enough to be represented by a double precision float and remain in the array.')\n","# Display 10 values of y.\n","pd.DataFrame(y, columns=['y']).head(10)"],"execution_count":185,"outputs":[{"output_type":"stream","text":["71,602 values of 1,000,000 y values are large enough to be represented by a double precision float and remain in the array.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9.120758e-90</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.759064e-109</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.236640e-133</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.793776e-282</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8.535806e-237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.971696e-28</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.357865e-28</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2.685447e-253</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2.651561e-123</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2.462258e-254</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               y\n","0   9.120758e-90\n","1  5.759064e-109\n","2  1.236640e-133\n","3  3.793776e-282\n","4  8.535806e-237\n","5   1.971696e-28\n","6   1.357865e-28\n","7  2.685447e-253\n","8  2.651561e-123\n","9  2.462258e-254"]},"metadata":{"tags":[]},"execution_count":185}]},{"cell_type":"markdown","metadata":{"id":"34wxMg9GKXu4"},"source":["## a) Harmonic Mean ($p = -1$)"]},{"cell_type":"markdown","metadata":{"id":"C2KChV0AKXu4"},"source":["### i) $\\vec{x}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCN_he0NKXu5","executionInfo":{"status":"ok","timestamp":1607649362600,"user_tz":300,"elapsed":1146,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"dec829a3-7fcd-4983-9b95-f153464bf78b"},"source":["a = generalized_mean(x, -1, weights=False)\n","b = generalized_mean_alt(x, -1, weights=False, norm_factor=100)\n","c = hmean(x)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":186,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 99.75633669505517. \n","The output from the generalized_mean_alt function is 99.75633669505517. \n","The output from the scipy/numpy function is 99.7563366950605. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XD20s_e5KXu5"},"source":["### ii) $\\vec{y}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4Fs6SQpKXu5","executionInfo":{"status":"ok","timestamp":1607649362602,"user_tz":300,"elapsed":1137,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"b5021a6c-739d-4c96-ee8f-7e8574a72847"},"source":["a = generalized_mean(y, -1, weights=False)\n","b = generalized_mean_alt(y, -1, weights=False, norm_factor=100)\n","c = hmean(y)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":187,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 0.0. \n","The output from the generalized_mean_alt function is 0.0. \n","The output from the scipy/numpy function is 0.0. \n","Are these reasonably close? Yes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: overflow encountered in reciprocal\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: overflow encountered in power\n","/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:404: RuntimeWarning: overflow encountered in true_divide\n","  return size / np.sum(1.0 / a, axis=axis, dtype=dtype)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7JdIib-6KXu6"},"source":["## b) $-\\frac{2}{3}$ Mean ($p = -\\frac{2}{3}$)\n","\n","There is not $-\\frac{2}{3}$ mean function in numpy or scipy to compare to, so I just compared the two generalized mean functions."]},{"cell_type":"markdown","metadata":{"id":"nuqt8yPtKXu6"},"source":["### i) $\\vec{x}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFDm75MJKXu6","executionInfo":{"status":"ok","timestamp":1607649363011,"user_tz":300,"elapsed":1535,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"471a3565-d927-4dc1-d64b-2042b80611a8"},"source":["a = generalized_mean(x, -2/3, weights=False)\n","b = generalized_mean_alt(x, -2/3, weights=False, norm_factor=100)\n","\n","if np.isclose(a, b):\n","    c = 'Yes'\n","else:\n","    c = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nAre these reasonably close? {c}.')"],"execution_count":188,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 99.79834197665035. \n","The output from the generalized_mean_alt function is 99.7983419766507. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m-qHDwNpKXu7"},"source":["### ii) $\\vec{y}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjdwhiYYKXu7","executionInfo":{"status":"ok","timestamp":1607649363013,"user_tz":300,"elapsed":1528,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"70db242b-9db0-4820-9be4-86308a4ecb2f"},"source":["a = generalized_mean(y, -2/3, weights=False)\n","b = generalized_mean_alt(y, -2/3, weights=False, norm_factor=100)\n","\n","if np.isclose(a, b):\n","    c = 'Yes'\n","else:\n","    c = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nAre these reasonably close? {c}.')"],"execution_count":189,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 5.4621e-319. \n","The output from the generalized_mean_alt function is 5.4621e-319. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbia-046KXu7"},"source":["## c) Geometric Mean ($p = 0$)"]},{"cell_type":"markdown","metadata":{"id":"6Lc8Tt7RKXu7"},"source":["### i) $\\vec{x}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MegLBVtKXu8","executionInfo":{"status":"ok","timestamp":1607649363200,"user_tz":300,"elapsed":1705,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"160b4eba-683d-41c2-911a-efccfde0a700"},"source":["a = generalized_mean(x, 0, weights=False)\n","b = generalized_mean_alt(x, 0, weights=False, norm_factor=100)\n","c = gmean(x)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":190,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 99.88219035772059. \n","The output from the generalized_mean_alt function is 99.88219035772059. \n","The output from the scipy/numpy function is 99.88219035772121. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HnpJGMZkKXu8"},"source":["### ii) $\\vec{y}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaREpYhHKXu8","executionInfo":{"status":"ok","timestamp":1607649363430,"user_tz":300,"elapsed":1925,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"d850d9e8-32da-4c13-dbef-2d342f34236b"},"source":["a = generalized_mean(y, 0, weights=False)\n","b = generalized_mean_alt(y, 0, weights=False, norm_factor=100)\n","c = gmean(y)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":191,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 3.76877219250309e-156. \n","The output from the generalized_mean_alt function is 3.76877219250309e-156. \n","The output from the scipy/numpy function is 3.7687721925033044e-156. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p78iU-HeKXu8"},"source":["## d) Arithmetic Mean ($p = 1$)"]},{"cell_type":"markdown","metadata":{"id":"r6A3np0XKXu9"},"source":["### i) $\\vec{x}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy-5414SKXu9","executionInfo":{"status":"ok","timestamp":1607649363584,"user_tz":300,"elapsed":2071,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"2278caff-769b-484e-b61f-865805ede6b7"},"source":["a = generalized_mean(x, 1, weights=False)\n","b = generalized_mean_alt(x, 1, weights=False, norm_factor=100)\n","c = np.mean(x)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":192,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 100.00756073257767. \n","The output from the generalized_mean_alt function is 100.00756073257769. \n","The output from the scipy/numpy function is 100.00756073257772. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h4_t_xBUKXu9"},"source":["### ii) $\\vec{y}$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUzZHe6HKXu9","executionInfo":{"status":"ok","timestamp":1607649363585,"user_tz":300,"elapsed":2062,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"873528b4-19c0-4326-98df-268404accfc8"},"source":["a = generalized_mean(y, 1, weights=False)\n","b = generalized_mean_alt(y, 1, weights=False, norm_factor=100)\n","c = np.mean(y)\n","\n","if np.isclose(a, b) & np.isclose(b, c):\n","    d = 'Yes'\n","else:\n","    d = 'No'\n","    \n","print(f'The output from the generalized_mean function is {a}.', \n","      f'\\nThe output from the generalized_mean_alt function is {b}.',\n","      f'\\nThe output from the scipy/numpy function is {c}.',\n","      f'\\nAre these reasonably close? {d}.')"],"execution_count":193,"outputs":[{"output_type":"stream","text":["The output from the generalized_mean function is 0.013931843947880829. \n","The output from the generalized_mean_alt function is 0.013931843947880829. \n","The output from the scipy/numpy function is 0.01393184394788079. \n","Are these reasonably close? Yes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K08rALhgKXu-"},"source":["## e) Final Tests\n","\n","I created a numpy array of $4.95 * 10^{-323}$ repeated 1,000,000 times. $4.95 * 10^{-323}$ is 1 order of magnitude from being as small as a number that can be represented with a double precision float. I then multiplied each element in that vector of repeats by $z_i$, where $Z \\sim N(10, 1)$ to generate random numbers close to the maximum precision. Neither function threw an error trying to calculate the $\\frac{-2}{3}$ mean, so it seems like the **generalized_mean_alt** function is not needed and the simpler **generalized_mean** function is what we should use."]},{"cell_type":"markdown","metadata":{"id":"_lIWDH6kNYYu"},"source":["### i) On 1,000,000 Small Random Numbers Close to the 64-bit Precision Limit"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ChWSTswKXu-","executionInfo":{"status":"ok","timestamp":1607649364081,"user_tz":300,"elapsed":2549,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"a2a0d02f-1ed7-417d-ce47-953b98e40d35"},"source":["n = 1000000\n","\n","z = np.repeat(4.95*10**(-323), n) * np.random.normal(loc=10, scale=1, size=n)**2\n","\n","generalized_mean(z, r=-2/3, weights=False), generalized_mean_alt(z, r=-2/3, weights=False, norm_factor=100)"],"execution_count":194,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4.82e-321, 4.82e-321)"]},"metadata":{"tags":[]},"execution_count":194}]},{"cell_type":"markdown","metadata":{"id":"aZECABu1N_CO"},"source":["### ii) On 100,000 Small and Large Numbers at the limit of 64-bit Precision"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eD5HD6gL_Qw","executionInfo":{"status":"ok","timestamp":1607649364082,"user_tz":300,"elapsed":2541,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"69f7af5f-2e8e-40fc-f5e0-fcb8604e4ba0"},"source":["float_info = np.finfo(np.float64)\r\n","print(f'Largest Number: {float_info.max}')\r\n","smallest_num = float_info.tiny\r\n","print(f'Smallest Number: {smallest_num}')"],"execution_count":195,"outputs":[{"output_type":"stream","text":["Largest Number: 1.7976931348623157e+308\n","Smallest Number: 2.2250738585072014e-308\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CSSa_QdURY6G","executionInfo":{"status":"ok","timestamp":1607649364083,"user_tz":300,"elapsed":2532,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}}},"source":["n = 100000"],"execution_count":196,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDjlnCikQpDl","executionInfo":{"status":"ok","timestamp":1607649364252,"user_tz":300,"elapsed":2695,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"21d78d1e-5fde-4d94-cad3-4539921a1c8b"},"source":["smallest = np.repeat(smallest_num, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(smallest, -1), \r\n","      generalized_mean(smallest, -2/3), \r\n","      generalized_mean(smallest, 0), \r\n","      generalized_mean(smallest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(smallest, -1, norm_factor=100), \r\n","      generalized_mean_alt(smallest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 0, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 1, norm_factor=100))"],"execution_count":197,"outputs":[{"output_type":"stream","text":["generalized_mean\n","0.0 2.2250738585072256e-308 2.2250738584167024e-308 0.0\n","\n","generalized_mean_alt\n","0.0 2.2250738585073037e-308 2.2250738584167024e-308 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AM0Zvy8sSenL","executionInfo":{"status":"ok","timestamp":1607649364253,"user_tz":300,"elapsed":2685,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"3305aa70-1386-4fc2-8ce9-651a07fcb5bd"},"source":["smallest = np.repeat(smallest_num*(10**5), n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(smallest, -1), \r\n","      generalized_mean(smallest, -2/3), \r\n","      generalized_mean(smallest, 0), \r\n","      generalized_mean(smallest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(smallest, -1, norm_factor=100), \r\n","      generalized_mean_alt(smallest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 0, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 1, norm_factor=100))"],"execution_count":198,"outputs":[{"output_type":"stream","text":["generalized_mean\n","2.22507385850728e-303 2.2250738585072512e-303 2.2250738585529423e-303 0.0\n","\n","generalized_mean_alt\n","2.225073858507255e-303 2.2250738585072797e-303 2.2250738585529423e-303 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLf1zFM9S0Ck","executionInfo":{"status":"ok","timestamp":1607649364439,"user_tz":300,"elapsed":2862,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"d0717fa1-ecf0-40db-ace5-39e8e8f473ec"},"source":["smallest = np.repeat(smallest_num*(10**292), n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(smallest, -1), \r\n","      generalized_mean(smallest, -2/3), \r\n","      generalized_mean(smallest, 0), \r\n","      generalized_mean(smallest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(smallest, -1, norm_factor=100), \r\n","      generalized_mean_alt(smallest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 0, norm_factor=100),\r\n","      generalized_mean_alt(smallest, 1, norm_factor=100))"],"execution_count":199,"outputs":[{"output_type":"stream","text":["generalized_mean\n","2.2250738585073513e-16 2.225073858507366e-16 2.225073858501767e-16 1.1102230246251565e-16\n","\n","generalized_mean_alt\n","2.22507385850735e-16 2.225073858507355e-16 2.225073858501767e-16 1.1102230246251565e-16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xI9oKQWtMdeQ","executionInfo":{"status":"ok","timestamp":1607649364596,"user_tz":300,"elapsed":3010,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"410088e4-3b45-421d-d144-a93ffd6d96ae"},"source":["largest = np.repeat(1.7976931348623157e+308, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(largest, -1), \r\n","      generalized_mean(largest, -2/3), \r\n","      generalized_mean(largest, 0), \r\n","      generalized_mean(largest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(largest, -1, norm_factor=100), \r\n","      generalized_mean_alt(largest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(largest, 0, norm_factor=100),\r\n","      generalized_mean_alt(largest, 1, norm_factor=100))"],"execution_count":200,"outputs":[{"output_type":"stream","text":["generalized_mean\n","inf inf 1.7976931348087272e+308 inf\n","\n","generalized_mean_alt\n","inf inf 1.7976931348087272e+308 inf\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: divide by zero encountered in double_scalars\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: overflow encountered in power\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjVdpqAzOZI0","executionInfo":{"status":"ok","timestamp":1607649364597,"user_tz":300,"elapsed":2997,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"970199c2-3825-45c3-8948-e10a1ba90ede"},"source":["largest = np.repeat(1.7976931348623157e+303, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(largest, -1), \r\n","      generalized_mean(largest, -2/3), \r\n","      generalized_mean(largest, 0), \r\n","      generalized_mean(largest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(largest, -1, norm_factor=100), \r\n","      generalized_mean_alt(largest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(largest, 0, norm_factor=100),\r\n","      generalized_mean_alt(largest, 1, norm_factor=100))"],"execution_count":201,"outputs":[{"output_type":"stream","text":["generalized_mean\n","inf inf 1.7976931348952634e+303 1.7976931348622524e+303\n","\n","generalized_mean_alt\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["inf inf 1.7976931348952634e+303 1.7976931348622725e+303\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1Pwt9cfOen6","executionInfo":{"status":"ok","timestamp":1607649364950,"user_tz":300,"elapsed":3337,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"c66b90da-0953-4602-e978-f58ed0762437"},"source":["largest = np.repeat(1.7976931348623157e+24, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(largest, -1), \r\n","      generalized_mean(largest, -2/3), \r\n","      generalized_mean(largest, 0), \r\n","      generalized_mean(largest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(largest, -1, norm_factor=100), \r\n","      generalized_mean_alt(largest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(largest, 0, norm_factor=100),\r\n","      generalized_mean_alt(largest, 1, norm_factor=100))"],"execution_count":202,"outputs":[{"output_type":"stream","text":["generalized_mean\n","inf 3.022314549036573e+23 1.7976931348667672e+24 1.7976931348623925e+24\n","\n","generalized_mean_alt\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["inf inf 1.7976931348667672e+24 1.7976931348623962e+24\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgZ9f7xNQGOc","executionInfo":{"status":"ok","timestamp":1607649364952,"user_tz":300,"elapsed":3324,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"0fd2448d-f142-4ba5-c1b7-9beedd6ff40d"},"source":["largest = np.repeat(1.7976931348623157e+23, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(largest, -1), \r\n","      generalized_mean(largest, -2/3), \r\n","      generalized_mean(largest, 0), \r\n","      generalized_mean(largest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(largest, -1, norm_factor=100), \r\n","      generalized_mean_alt(largest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(largest, 0, norm_factor=100),\r\n","      generalized_mean_alt(largest, 1, norm_factor=100))"],"execution_count":203,"outputs":[{"output_type":"stream","text":["generalized_mean\n","inf 3.022314549036573e+23 1.797693134856093e+23 1.7976931348622298e+23\n","\n","generalized_mean_alt\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["inf 3.022314549036573e+23 1.797693134856093e+23 1.79769313486223e+23\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giq5KlYfQP0v","executionInfo":{"status":"ok","timestamp":1607649365100,"user_tz":300,"elapsed":3442,"user":{"displayName":"John Clements","photoUrl":"","userId":"00332780842022777712"}},"outputId":"e46ce225-5226-40af-946f-813d29f4e86e"},"source":["largest = np.repeat(1.7976931348623157e+16, n)\r\n","\r\n","print('generalized_mean')\r\n","print(generalized_mean(largest, -1), \r\n","      generalized_mean(largest, -2/3), \r\n","      generalized_mean(largest, 0), \r\n","      generalized_mean(largest, 1))\r\n","print('\\ngeneralized_mean_alt')\r\n","print(generalized_mean_alt(largest, -1, norm_factor=100), \r\n","      generalized_mean_alt(largest, -2/3, norm_factor=100),\r\n","      generalized_mean_alt(largest, 0, norm_factor=100),\r\n","      generalized_mean_alt(largest, 1, norm_factor=100))"],"execution_count":204,"outputs":[{"output_type":"stream","text":["generalized_mean\n","9007199254740992.0 1.8008627614458812e+16 1.7976931348664958e+16 1.7976931348621944e+16\n","\n","generalized_mean_alt\n","9007199254740992.0 1.8008627614458812e+16 1.7976931348664958e+16 1.7976931348621924e+16\n"],"name":"stdout"}]}]}