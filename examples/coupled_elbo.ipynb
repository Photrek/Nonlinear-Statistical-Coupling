{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing NSC lib v0.0.4.1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import scipy\n",
    "import ipdb\n",
    "\n",
    "# From nsc lib\n",
    "import nsc\n",
    "from nsc import distributions as nsd\n",
    "# from nsc.math import function as nsc_func\n",
    "nsd = nsc.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-06, 5.01049905e-04, 1.00109981e-03, ...,\n",
       "       4.99899990e+00, 4.99949995e+00, 5.00000000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_sample of linearly spaced numbers, starting from CLOSE to 0\n",
    "X = np.linspace(1e-6, 5, n_sample)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.        , -11.99759976, -11.99519952, ...,  11.99519952,\n",
       "        11.99759976,  12.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.linspace(-12*scale, 12*scale, n_sample)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e-06, -1.20000000e+01],\n",
       "       [ 5.01049905e-04, -1.19975998e+01],\n",
       "       [ 1.00109981e-03, -1.19951995e+01],\n",
       "       ...,\n",
       "       [ 4.99899990e+00,  1.19951995e+01],\n",
       "       [ 4.99949995e+00,  1.19975998e+01],\n",
       "       [ 5.00000000e+00,  1.20000000e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2D = np.column_stack((X, X2))\n",
    "X_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ELBO formula:**\n",
    "    $$\\Large ELBO = L(\\theta, \\phi, x^{(i)}) =\\\\\\\\\\Large-D_{KL}(q_\\phi(z| x^{(i)}) || p_\\theta(z)) + E_{q_\\phi(z|x^{(i)})}[log_\\kappa p_\\theta(x^{(i)} | z)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both encoding_dist and prior are **tfp.distributions.MultivariateNormalDiag**, although likely with different batch_shapes.\n",
    "- Output of tfd.kl_divergence is a 1D tensor.\n",
    "- Input of x is a nD tensor.\n",
    "- Output of sampled_decoding_dist.log_prob(x) is a 1D tensor of same dim as tfd.kl_divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior, p(z) - a standard bivariate Gaussian\n",
    "# prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbo = -tfd.kl_divergence(encoding_dist, prior) + sampled_decoding_dist.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coupled ELBO formula:**\n",
    "    $$\\Large Coupled ELBO = L(\\theta, \\phi, \\kappa, \\alpha, d, x^{(i)}) = -D_{KL}(q_\\phi^{\\frac{\\alpha}{1+d\\kappa}}(z| x^{(i)}) || p_\\theta^{\\frac{\\alpha}{1+d\\kappa}}(z)) + E_{q_\\phi^{(a, d, \\kappa)}(z|x^{(i)})}[log_\\kappa p_\\theta^{\\frac{\\alpha}{1+d\\kappa}}(x^{(i)} | z)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 0.1\n",
    "alpha = 2\n",
    "dim = 2\n",
    "z_dim = 2\n",
    "batch_size = 64\n",
    "sample_n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_loc, encoding_scale = [[0., 1.]], [[1., 2.]]\n",
    "encoding_loc, encoding_scale\n",
    "type(encoding_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1],\n",
       "  [1, 2],\n",
       "  [2, 3],\n",
       "  [3, 4],\n",
       "  [4, 5],\n",
       "  [5, 6],\n",
       "  [6, 7],\n",
       "  [7, 8],\n",
       "  [8, 9],\n",
       "  [9, 10],\n",
       "  [10, 11],\n",
       "  [11, 12],\n",
       "  [12, 13],\n",
       "  [13, 14],\n",
       "  [14, 15],\n",
       "  [15, 16],\n",
       "  [16, 17],\n",
       "  [17, 18],\n",
       "  [18, 19],\n",
       "  [19, 20],\n",
       "  [20, 21],\n",
       "  [21, 22],\n",
       "  [22, 23],\n",
       "  [23, 24],\n",
       "  [24, 25],\n",
       "  [25, 26],\n",
       "  [26, 27],\n",
       "  [27, 28],\n",
       "  [28, 29],\n",
       "  [29, 30],\n",
       "  [30, 31],\n",
       "  [31, 32],\n",
       "  [32, 33],\n",
       "  [33, 34],\n",
       "  [34, 35],\n",
       "  [35, 36],\n",
       "  [36, 37],\n",
       "  [37, 38],\n",
       "  [38, 39],\n",
       "  [39, 40],\n",
       "  [40, 41],\n",
       "  [41, 42],\n",
       "  [42, 43],\n",
       "  [43, 44],\n",
       "  [44, 45],\n",
       "  [45, 46],\n",
       "  [46, 47],\n",
       "  [47, 48],\n",
       "  [48, 49],\n",
       "  [49, 50],\n",
       "  [50, 51],\n",
       "  [51, 52],\n",
       "  [52, 53],\n",
       "  [53, 54],\n",
       "  [54, 55],\n",
       "  [55, 56],\n",
       "  [56, 57],\n",
       "  [57, 58],\n",
       "  [58, 59],\n",
       "  [59, 60],\n",
       "  [60, 61],\n",
       "  [61, 62],\n",
       "  [62, 63],\n",
       "  [63, 64]],\n",
       " [[1, 2],\n",
       "  [2, 3],\n",
       "  [3, 4],\n",
       "  [4, 5],\n",
       "  [5, 6],\n",
       "  [6, 7],\n",
       "  [7, 8],\n",
       "  [8, 9],\n",
       "  [9, 10],\n",
       "  [10, 11],\n",
       "  [11, 12],\n",
       "  [12, 13],\n",
       "  [13, 14],\n",
       "  [14, 15],\n",
       "  [15, 16],\n",
       "  [16, 17],\n",
       "  [17, 18],\n",
       "  [18, 19],\n",
       "  [19, 20],\n",
       "  [20, 21],\n",
       "  [21, 22],\n",
       "  [22, 23],\n",
       "  [23, 24],\n",
       "  [24, 25],\n",
       "  [25, 26],\n",
       "  [26, 27],\n",
       "  [27, 28],\n",
       "  [28, 29],\n",
       "  [29, 30],\n",
       "  [30, 31],\n",
       "  [31, 32],\n",
       "  [32, 33],\n",
       "  [33, 34],\n",
       "  [34, 35],\n",
       "  [35, 36],\n",
       "  [36, 37],\n",
       "  [37, 38],\n",
       "  [38, 39],\n",
       "  [39, 40],\n",
       "  [40, 41],\n",
       "  [41, 42],\n",
       "  [42, 43],\n",
       "  [43, 44],\n",
       "  [44, 45],\n",
       "  [45, 46],\n",
       "  [46, 47],\n",
       "  [47, 48],\n",
       "  [48, 49],\n",
       "  [49, 50],\n",
       "  [50, 51],\n",
       "  [51, 52],\n",
       "  [52, 53],\n",
       "  [53, 54],\n",
       "  [54, 55],\n",
       "  [55, 56],\n",
       "  [56, 57],\n",
       "  [57, 58],\n",
       "  [58, 59],\n",
       "  [59, 60],\n",
       "  [60, 61],\n",
       "  [61, 62],\n",
       "  [62, 63],\n",
       "  [63, 64],\n",
       "  [64, 65]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding_loc, encoding_scale = [[0., 1.]], [[1., 2.]]\n",
    "encoding_loc, encoding_scale = [], []\n",
    "for i in range(batch_size):\n",
    "    encoding_loc.append([i, i+1])\n",
    "    encoding_scale.append([i+1, i+2])\n",
    "encoding_loc, encoding_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "scale must be positive definite, but not necessarily symmetric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9621c70b3bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m coupled_encoding_dist = nsd.MultivariateCoupledNormal(loc=encoding_loc,\n\u001b[1;32m     16\u001b[0m                                                       \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                       \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                                                       )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsc/lib/python3.7/site-packages/nsc/distributions/multivariate_coupled_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, kappa, alpha, validate_args)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Ensure that scale is indeed positive definite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_positive_definite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scale must be positive definite, but not necessarily symmetric.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Credit: https://stackoverflow.com/questions/16266720/find-out-if-matrix-is-positive-definite-with-numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: scale must be positive definite, but not necessarily symmetric."
     ]
    }
   ],
   "source": [
    "# Using dummy prior, enncoding_dist, and sampled_decoding_dist\n",
    "\n",
    "# Coupled Prior: p(z)\n",
    "coupled_prior = nsd.MultivariateCoupledNormal(loc=np.zeros(z_dim),\n",
    "                                              scale=np.ones(z_dim),\n",
    "                                              kappa=kappa, alpha=alpha\n",
    "                                              )\n",
    "\n",
    "# Coupled Encoding Distribution: q(z|x)\n",
    "# Have batch_shape=[64] and event_shape=[2]\n",
    "encoding_loc, encoding_scale = [], []\n",
    "for i in range(batch_size):\n",
    "    encoding_loc.append([i, i+1])\n",
    "    encoding_scale.append([i+1, i+2])\n",
    "coupled_encoding_dist = nsd.MultivariateCoupledNormal(loc=encoding_loc,\n",
    "                                                      scale=encoding_scale,\n",
    "                                                      kappa=0.1\n",
    "                                                      )\n",
    "\n",
    "# Coupled Sampled Decoding Distribution: p(x|z)\n",
    "coupled_sampled_decoding_dist = nsd.MultivariateCoupledNormal(loc=np.zeros(z_dim),\n",
    "                                                              scale=np.ones(z_dim),\n",
    "                                                              kappa=0.1\n",
    "                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coupled KL-Divergence\n",
    "coupled_encoding_dist.kl_divergence(coupled_prior, root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19315209e-08, 1.19583321e-08, 1.19852079e-08, ...,\n",
       "       4.85875496e-09, 4.84856698e-09, 4.83840196e-09])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coupled Cross-entropy\n",
    "coupled_sampled_decoding_dist.prob(X_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coupled ELBO\n",
    "coupled_elbo = -coupled_encoding_dist.kl_divergence(coupled_prior) + \\\n",
    "                coupled_sampled_decoding_dist.prob(X_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19315209e-08, 1.19583321e-08, 1.19852079e-08, ...,\n",
       "       4.85875496e-09, 4.84856698e-09, 4.83840196e-09])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=12.006604843648898>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(coupled_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-12.006604843648898>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function\n",
    "-tf.reduce_sum(coupled_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsc",
   "language": "python",
   "name": "nsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
